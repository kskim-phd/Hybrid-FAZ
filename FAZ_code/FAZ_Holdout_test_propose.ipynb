{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import *\n",
    "from skimage.filters import *\n",
    "from skimage.feature import *\n",
    "from skimage.transform import *\n",
    "from skimage.morphology import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "import skimage\n",
    "from skimage.util import *\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import draw\n",
    "from util import *\n",
    "import opsfaz as faz\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import natsort\n",
    "import glob\n",
    "import pdb\n",
    "import pickle\n",
    "\n",
    "# seed setting\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(17)\n",
    "\n",
    "def roundness(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    convex = convex_hull_image(img)\n",
    "    convex_perimeter = perimeter(convex)\n",
    "    \n",
    "    return (4 * math.pi * regions[0].area) / convex_perimeter ** 2\n",
    "\n",
    "def solidity(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    convex = convex_hull_image(img)\n",
    "    convex_regions = regionprops(convex.astype(int))\n",
    "    if len(convex_regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    \n",
    "    return regions[0].area / convex_regions[0].area\n",
    "\n",
    "def eccentricity(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    \n",
    "    return regions[0].minor_axis_length / regions[0].major_axis_length\n",
    "\n",
    "def compactness(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "\n",
    "    return (4 * math.pi * regions[0].area)/(perimeter(img))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_ex(data, label):\n",
    "    cols = {\n",
    "    'roundness': [],\n",
    "    'solidity': [],\n",
    "    'eccentricity': [],\n",
    "    'compactness': [],\n",
    "    }\n",
    "    area_lst = []\n",
    "    age_lst = []\n",
    "    gender_lst = []\n",
    "    scheme_lst = []\n",
    "    label_lst = []\n",
    "\n",
    "    for img_path in tqdm(data):\n",
    "        data = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        data = data/255\n",
    "        x, y = data.shape \n",
    "        size = data.shape\n",
    "        \n",
    "        mm = 3\n",
    "        deep = 0\n",
    "        precision = 0 # \n",
    "        imOCT = np.zeros((size[0],size[1]),np.float64)\n",
    "        contours,_ = cv2.findContours(data.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cogidos = []\n",
    "        cnt,cogidos = higest_contour (contours, cogidos)\n",
    "        m = cv2.contourArea(cnt)\n",
    "        fazAreainMM = m*(mm*mm)/(size[0]*size[1])\n",
    "\n",
    "        im = np.zeros((size[0],size[1]), np.uint8)\n",
    "        cv2.drawContours(im, [cnt], 0, (255,255,255), -1)\n",
    "        im = im[:]/255\n",
    "        \n",
    "        # make region growing\n",
    "        \n",
    "        reg = region_growing(imOCT, im*1.0, fazAreainMM, 0, 4, precision)\n",
    "\n",
    "        reg = morph ('open', reg, 3)\n",
    "        reg = morph ('closed', reg, 3)\n",
    "        image1 = cv2.convertScaleAbs(reg) \n",
    "        contours, h = cv2.findContours(image1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cogidos = []\n",
    "        cnt,cogidos = higest_contour (contours, cogidos)\n",
    "\n",
    "        m = cv2.contourArea(cnt)\n",
    "        fazAreainMM = m*(mm*mm)/(size[0]*size[1])\n",
    "        area = fazAreainMM\n",
    "        for col in cols:\n",
    "            cols[col].append(globals()[col](data))\n",
    "        num = int(str(img_path).split(\"/\")[-1].split(\" \")[0].split(\"_\")[-1])\n",
    "        Later = str(img_path).split(\"/\")[-1].split(\".\")[0].split(\" \")[-1]\n",
    "        df = pd.read_excel('/'.join(os.path.dirname(os.path.realpath(\"__file__\")).split('/')[:-1])+\"/AD_clinical_Holdout.xlsx\")\n",
    "        df[df[\"patients\"]==num]\n",
    "        right = df[df.columns[:15].tolist()]\n",
    "        left = df[df.columns[15:].tolist()]\n",
    "        right = right.fillna(right.shift(1))\n",
    "        df = pd.concat([right,left],axis=1)\n",
    "        area_lst.append(area)\n",
    "        scheme_lst.append(int(num))\n",
    "        age_lst.append(int(df[df[\"patients\"]==num][\"Age\"].tolist()[0]))\n",
    "        gender_lst.append(int(df[df[\"patients\"]==num][\"Sex\"].tolist()[0]))\n",
    "        z = df[df[\"patients\"]==num]\n",
    "        label_lst.append(label)\n",
    "        \n",
    "    df = pd.DataFrame(cols)\n",
    "    fold = pd.DataFrame(scheme_lst)\n",
    "    df['label'] = label_lst\n",
    "    df['area'] = area_lst\n",
    "    df[\"age\"] = age_lst\n",
    "    df[\"gender\"] = gender_lst\n",
    "    fold[\"scheme_num\"] = scheme_lst\n",
    "\n",
    "    return df,fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:09<00:00,  3.15it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "AD_scp_ex = []\n",
    "for i in Path('/'.join(os.path.dirname(os.path.realpath(\"__file__\")).split('/')[:-1])+\"/Holdout_proposed_AI/AD\").iterdir(): \n",
    "    if 'AD' in str(i):                   \n",
    "        AD_scp_ex.append(i)\n",
    "SCD_scp_ex = []\n",
    "for i in Path('/'.join(os.path.dirname(os.path.realpath(\"__file__\")).split('/')[:-1])+\"/Holdout_proposed_AI/SCD\").iterdir(): \n",
    "    if 'SCD' in str(i):                   \n",
    "        SCD_scp_ex.append(i)\n",
    "\n",
    "AD_scp_ex,fold_num1_ex = make_df_ex(AD_scp_ex,\"AD_scp\")\n",
    "SCD_scp_ex,fold_num2_ex = make_df_ex(SCD_scp_ex, \"SCD_scp\")\n",
    "fold_AD_ex = pd.concat([fold_num1_ex,AD_scp_ex[\"label\"]], axis=1).reset_index(drop=True)\n",
    "fold_SCD_ex = pd.concat([fold_num2_ex,SCD_scp_ex[\"label\"]], axis=1).reset_index(drop=True)\n",
    "# fold_ex = pd.concat([fold_AD_ex,fold_SCD_ex]).reset_index(drop=True)\n",
    "fold_ex = pd.concat([fold_SCD_ex,fold_AD_ex]).reset_index(drop=True)\n",
    "fold_dup_ex = fold_ex.drop_duplicates().reset_index(drop=True)\n",
    "# df_ex = pd.concat([AD_scp_ex,SCD_scp_ex]).reset_index(drop=True)\n",
    "df_ex = pd.concat([SCD_scp_ex,AD_scp_ex]).reset_index(drop=True)\n",
    "df_ex.dropna(axis=1, inplace=True)\n",
    "cols_ex = df_ex.columns.tolist()\n",
    "cols_ex.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:0.545± 0.051, Specificity:0.838± 0.064, Accuracy:0.649± 0.043, AUC:0.720± 0.048 \n"
     ]
    }
   ],
   "source": [
    "#Proposed\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import *\n",
    "import warnings\n",
    "import joblib\n",
    "# save model\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels_ex= le.fit_transform(fold_ex[\"label\"])\n",
    "\n",
    "acc_sum = 0\n",
    "score_sum = 0\n",
    "acc_lst = []\n",
    "auc_lst = []\n",
    "y_lst = []\n",
    "pred_lst = []\n",
    "label_lst=[]\n",
    "fold_num = []\n",
    "\n",
    "#confusion_matrix\n",
    "spec_lst = []\n",
    "sens_lst = []\n",
    "acc_lst = []\n",
    "set_seed(0)\n",
    "for i in range(5):\n",
    "    lr_clf = joblib.load('/'.join(os.path.dirname(os.path.realpath(\"__file__\")).split('/')[:-1])+'/FAZ_code/Proposed_weight/'+'lgb_'+str(i)+'.pkl')\n",
    "    X_test =  df_ex[cols_ex]\n",
    "    y_test = labels_ex\n",
    "    pred = lr_clf.predict(X_test)\n",
    "    preds = lr_clf.predict_proba(X_test)\n",
    "    score = roc_auc_score(y_test, preds[:, 1])\n",
    "    y_lst.extend(y_test)\n",
    "    label_lst.extend(y_test)\n",
    "    pred_lst.extend(preds[:,0])\n",
    "    auc_lst.append(float(score))\n",
    "    fold_num.append(preds[:,0])\n",
    "    # print(y_test[16:29])\n",
    "    tp, fn, fp, tn = confusion_matrix(y_test,pred).ravel()\n",
    "    spec_lst.append(tn/(tn+fp))\n",
    "    sens_lst.append(tp/(tp+fn))\n",
    "    acc_lst.append((tn+tp)/(tn+fp+fn+tp))\n",
    "spec = np.array(spec_lst)\n",
    "sens = np.array(sens_lst)\n",
    "acc = np.array(acc_lst)\n",
    "print(f'Sensitivity:{sens.mean():.3f}± {sens.std():.3f}, Specificity:{spec.mean():.3f}± {spec.std():.3f}, Accuracy:{acc.mean():.3f}± {acc.std():.3f}, AUC:{np.array(auc_lst).mean():.3f}± {np.array(auc_lst).std():.3f} ')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
