{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0018ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import *\n",
    "from skimage.filters import *\n",
    "from skimage.feature import *\n",
    "from skimage.transform import *\n",
    "from skimage.morphology import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "import skimage\n",
    "from skimage.util import *\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import draw\n",
    "from util import *\n",
    "import opsfaz as faz\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import natsort\n",
    "import glob\n",
    "import pdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720ca91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed setting\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af95f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundness(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    convex = convex_hull_image(img)\n",
    "    convex_perimeter = perimeter(convex)\n",
    "    \n",
    "    return (4 * math.pi * regions[0].area) / convex_perimeter ** 2\n",
    "\n",
    "def solidity(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    convex = convex_hull_image(img)\n",
    "    convex_regions = regionprops(convex.astype(int))\n",
    "    if len(convex_regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    \n",
    "    return regions[0].area / convex_regions[0].area\n",
    "\n",
    "def eccentricity(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "    \n",
    "    return regions[0].minor_axis_length / regions[0].major_axis_length\n",
    "\n",
    "def compactness(img):\n",
    "    regions = regionprops(img.astype(int))\n",
    "    if len(regions) != 1:\n",
    "        raise('There are one more contours!')\n",
    "\n",
    "    return (4 * math.pi * regions[0].area)/(perimeter(img))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3434d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propsoed\n",
    "# Data Frame\n",
    "def make_df(data, label):\n",
    "    cols = {\n",
    "    'roundness': [],\n",
    "    'solidity': [],\n",
    "    'eccentricity': [],\n",
    "    'compactness': [],\n",
    "    }\n",
    "    area_lst = []\n",
    "    age_lst = []\n",
    "    gender_lst = []\n",
    "    scheme_lst = []\n",
    "    label_lst = []\n",
    "\n",
    "    for img_path in tqdm(data):\n",
    "        data = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        data = data/255\n",
    "        x, y = data.shape \n",
    "        size = data.shape\n",
    "        \n",
    "        mm = 3\n",
    "        deep = 0\n",
    "        precision = 0 # \n",
    "        imOCT = np.zeros((size[0],size[1]),np.float64)\n",
    "        contours,_ = cv2.findContours(data.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cogidos = []\n",
    "        cnt,cogidos = higest_contour (contours, cogidos)\n",
    "        m = cv2.contourArea(cnt)\n",
    "        fazAreainMM = m*(mm*mm)/(size[0]*size[1])\n",
    "\n",
    "        im = np.zeros((size[0],size[1]), np.uint8)\n",
    "        cv2.drawContours(im, [cnt], 0, (255,255,255), -1)\n",
    "        im = im[:]/255\n",
    "        \n",
    "        # make region growing\n",
    "        \n",
    "        reg = region_growing(imOCT, im*1.0, fazAreainMM, 0, 4, precision)\n",
    "\n",
    "        reg = morph ('open', reg, 3)\n",
    "        reg = morph ('closed', reg, 3)\n",
    "        image1 = cv2.convertScaleAbs(reg) \n",
    "        contours, h = cv2.findContours(image1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cogidos = []\n",
    "        cnt,cogidos = higest_contour (contours, cogidos)\n",
    "\n",
    "        m = cv2.contourArea(cnt)\n",
    "        fazAreainMM = m*(mm*mm)/(size[0]*size[1])\n",
    "        area = fazAreainMM\n",
    "        for col in cols:\n",
    "            cols[col].append(globals()[col](data))\n",
    "        num = int(str(img_path).split(\"/\")[-1].split(\" \")[0].split(\"_\")[-1])\n",
    "        Later = str(img_path).split(\"/\")[-1].split(\".\")[0].split(\" \")[-1]\n",
    "        df = pd.read_excel('/'.join(os.getcwd().split('/')[:-1])+\"/Alz_clinical.xlsx\")\n",
    "        df[df[\"Research number\"]==num]\n",
    "        right = df[df.columns[:15].tolist()]\n",
    "        left = df[df.columns[15:].tolist()]\n",
    "        right = right.fillna(right.shift(1))\n",
    "        df = pd.concat([right,left],axis=1)\n",
    "        area_lst.append(area)\n",
    "        scheme_lst.append(int(num))\n",
    "        age_lst.append(int(df[df[\"Research number\"]==num][\"Age\"].tolist()[0]))\n",
    "        gender_lst.append(int(df[df[\"Research number\"]==num][\"Sex\"].tolist()[0]))\n",
    "        z = df[df[\"Research number\"]==num]\n",
    "        label_lst.append(label)\n",
    "        \n",
    "    df = pd.DataFrame(cols)\n",
    "    fold = pd.DataFrame(scheme_lst)\n",
    "    df['label'] = label_lst\n",
    "    df['area'] = area_lst\n",
    "    df[\"age\"] = age_lst\n",
    "    df[\"gender\"] = gender_lst\n",
    "    fold[\"scheme_num\"] = scheme_lst\n",
    "\n",
    "    return df,fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00503bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline\n",
    "def make_dfs(data, label):\n",
    "    cols = {\n",
    "\n",
    "    }\n",
    "    area_lst = []\n",
    "    age_lst = []\n",
    "    gender_lst = []\n",
    "    scheme_lst = []\n",
    "    label_lst = []\n",
    "\n",
    "    for img_path in tqdm(data):\n",
    "        data = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
    "        data = data/255\n",
    "        x, y = data.shape \n",
    "        size = data.shape\n",
    "        \n",
    "        mm = 3\n",
    "        deep = 0\n",
    "        precision = 0 \n",
    "        imOCT = np.zeros((size[0],size[1]),np.float64)\n",
    "        contours,_ = cv2.findContours(data.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cogidos = []\n",
    "        cnt,cogidos = higest_contour (contours, cogidos)\n",
    "        m = cv2.contourArea(cnt)\n",
    "        fazAreainMM = m*(mm*mm)/(size[0]*size[1])\n",
    "\n",
    "        im = np.zeros((size[0],size[1]), np.uint8)\n",
    "        cv2.drawContours(im, [cnt], 0, (255,255,255), -1)\n",
    "        im = im[:]/255\n",
    "        \n",
    "        # make region growing\n",
    "        \n",
    "        reg = region_growing(imOCT, im*1.0, fazAreainMM, 0, 4, precision)\n",
    "\n",
    "        reg = morph ('open', reg, 3)\n",
    "        reg = morph ('closed', reg, 3)\n",
    "        image1 = cv2.convertScaleAbs(reg) \n",
    "        contours, h = cv2.findContours(image1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cogidos = []\n",
    "        cnt,cogidos = higest_contour (contours, cogidos)\n",
    "\n",
    "        m = cv2.contourArea(cnt)\n",
    "        fazAreainMM = m*(mm*mm)/(size[0]*size[1])\n",
    "        area = fazAreainMM\n",
    "        for col in cols:\n",
    "            cols[col].append(globals()[col](data))\n",
    "        num = int(str(img_path).split(\"/\")[-1].split(\" \")[0].split(\"_\")[-1])\n",
    "        Later = str(img_path).split(\"/\")[-1].split(\".\")[0].split(\" \")[-1]\n",
    "        df = pd.read_excel('/'.join(os.getcwd().split('/')[:-1])+\"/Alz_clinical.xlsx\")\n",
    "        df[df[\"Research number\"]==num]\n",
    "        right = df[df.columns[:15].tolist()]\n",
    "        left = df[df.columns[15:].tolist()]\n",
    "        right = right.fillna(right.shift(1))\n",
    "        df = pd.concat([right,left],axis=1)\n",
    "        area_lst.append(area)\n",
    "        scheme_lst.append(int(num))\n",
    "        age_lst.append(int(df[df[\"Research number\"]==num][\"Age\"].tolist()[0]))\n",
    "        gender_lst.append(int(df[df[\"Research number\"]==num][\"Sex\"].tolist()[0]))\n",
    "        z = df[df[\"Research number\"]==num]\n",
    "        label_lst.append(label)\n",
    "    df = pd.DataFrame(cols)\n",
    "    fold = pd.DataFrame(scheme_lst)\n",
    "    df['label'] = label_lst\n",
    "    df['area'] = area_lst\n",
    "    df[\"age\"] = age_lst\n",
    "    df[\"gender\"] = gender_lst\n",
    "    fold[\"scheme_num\"] = scheme_lst\n",
    "\n",
    "    return df,fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b52d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_scp = []\n",
    "with open('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/AD_pro.pkl\",\"rb\") as f :\n",
    "    AD = pickle.load(f)\n",
    "for i in AD:\n",
    "    AD_scp.append('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/AI_base_inference/AD/\"+i)\n",
    "SCD_scp = []\n",
    "with open('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/SCD_pro.pkl\",\"rb\") as l :\n",
    "    SCD = pickle.load(l)\n",
    "for i in SCD:\n",
    "    SCD_scp.append('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/AI_base_inference/SCD/\"+i)\n",
    "ADs_scp = []\n",
    "with open('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/AD_base.pkl\",\"rb\") as f :\n",
    "    ADs = pickle.load(f)\n",
    "for i in ADs:\n",
    "    ADs_scp.append('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/segmen_manual/AD/\"+i)\n",
    "SCDs_scp = []\n",
    "with open('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/SCD_base.pkl\",\"rb\") as l :\n",
    "    SCDs = pickle.load(l)\n",
    "for i in SCDs:\n",
    "    SCDs_scp.append('/'.join(os.getcwd().split('/')[:-1])+\"/Dataset/segmen_manual/SCD/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6614fd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:10<00:00,  2.98it/s]\n",
      "100%|██████████| 54/54 [00:16<00:00,  3.30it/s]\n",
      "100%|██████████| 31/31 [00:09<00:00,  3.36it/s]\n",
      "100%|██████████| 54/54 [00:15<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "AD_scp,fold_num1 = make_df(AD_scp,\"AD_scp\")\n",
    "SCD_scp,fold_num2 = make_df(SCD_scp, \"SCD_scp\")\n",
    "\n",
    "ADs_scp,folds_num1 = make_dfs(ADs_scp,\"ADs_scp\")\n",
    "SCDs_scp,folds_num2 = make_dfs(SCDs_scp, \"SCDs_scp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaa5a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_AD = pd.concat([fold_num1,AD_scp[\"label\"]], axis=1).reset_index(drop=True)\n",
    "fold_SCD = pd.concat([fold_num2,SCD_scp[\"label\"]], axis=1).reset_index(drop=True)\n",
    "fold = pd.concat([fold_AD,fold_SCD]).reset_index(drop=True)\n",
    "fold_dup = fold.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "fold_ADs = pd.concat([folds_num1,AD_scp[\"label\"]], axis=1).reset_index(drop=True)\n",
    "fold_SCDs = pd.concat([folds_num2,SCD_scp[\"label\"]], axis=1).reset_index(drop=True)\n",
    "folds = pd.concat([fold_ADs,fold_SCDs]).reset_index(drop=True)\n",
    "folds_dup = folds.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15d7643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([AD_scp,SCD_scp]).reset_index(drop=True)\n",
    "dfs = pd.concat([ADs_scp,SCDs_scp]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ff83bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1, inplace=True)\n",
    "dfs.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb0b6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols.remove('label')\n",
    "\n",
    "colss = dfs.columns.tolist()\n",
    "colss.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91a11933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1:0.7698181818181818\n",
      "fold2:0.7617821067821067\n",
      "fold3:0.6526190476190477\n",
      "fold4:0.707487012987013\n",
      "fold5:0.7227772227772228\n",
      "mean: 0.7228967143967143\n",
      "AUC std: 0.0421666253557142\n"
     ]
    }
   ],
   "source": [
    "#Proposed\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.concat([AD_scp,SCD_scp]).reset_index(drop=True)\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(fold_dup['label'])\n",
    "labels = le.fit_transform(fold[\"label\"])\n",
    "acc_sum = 0\n",
    "score_sum = 0\n",
    "acc_lst = []\n",
    "auc_lst = []\n",
    "y_lst = []\n",
    "pred_lst = []\n",
    "for i in range(5):\n",
    "    score_sum = 0\n",
    "    acc_sum = 0\n",
    "    set_seed(i)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for train_num, test_num in kf.split(fold_dup[\"scheme_num\"],label):\n",
    "        # print(test_num)\n",
    "        train_idxs = fold_dup[\"scheme_num\"].iloc[train_num]\n",
    "        train_idxs = fold[fold[\"scheme_num\"].isin(train_idxs)]\n",
    "        train_idx = train_idxs.index\n",
    "        test_idxs = fold_dup[\"scheme_num\"].iloc[test_num]\n",
    "        test_idxs = fold[fold[\"scheme_num\"].isin(test_idxs)]\n",
    "        test_idx = test_idxs.index\n",
    "        X_train, X_test = df[cols].iloc[train_idx], df[cols].iloc[test_idx]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "        lr_clf = LGBMClassifier(n_estimators=400, learning_rate=0.3, max_depth=3)\n",
    "        lr_clf.fit(X_train,y_train)       \n",
    "        pred = lr_clf.predict(X_test)\n",
    "        preds = lr_clf.predict_proba(X_test)\n",
    "        score = roc_auc_score(y_test, preds[:, 1])\n",
    "        y_lst.extend(y_test)\n",
    "        pred_lst.extend(preds)\n",
    "        auc_lst.append(float(score))\n",
    "\n",
    "fold1 = auc_lst[0] + auc_lst[0+5] + auc_lst[0+10] + auc_lst[0+15] + auc_lst[0+20]\n",
    "fold2 = auc_lst[1] + auc_lst[0+6] + auc_lst[0+11] + auc_lst[0+16] + auc_lst[0+21]\n",
    "fold3 = auc_lst[2] + auc_lst[0+7] + auc_lst[0+12] + auc_lst[0+17] + auc_lst[0+22]\n",
    "fold4 = auc_lst[3] + auc_lst[0+8] + auc_lst[0+13] + auc_lst[0+18] + auc_lst[0+23]\n",
    "fold5 = auc_lst[4] + auc_lst[0+9] + auc_lst[0+14] + auc_lst[0+19] + auc_lst[0+24]\n",
    "\n",
    "print(f'fold1:{fold1/5}')\n",
    "print(f'fold2:{fold2/5}')\n",
    "print(f'fold3:{fold3/5}')\n",
    "print(f'fold4:{fold4/5}')\n",
    "print(f'fold5:{fold5/5}')\n",
    "print(f'mean: {np.array(auc_lst).sum()/25}')\n",
    "print(f'AUC std: {np.std((fold1/5,fold2/5,fold3/5,fold4/5,fold5/5))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "737ffd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold1:0.5194381914381915\n",
      "fold2:0.645995670995671\n",
      "fold3:0.4986531986531986\n",
      "fold4:0.607491341991342\n",
      "fold5:0.6838394938394938\n",
      "mean: 0.5910835793835794\n",
      "AUC std: 0.07150475374598339\n"
     ]
    }
   ],
   "source": [
    "#Baseline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "dfs = pd.concat([ADs_scp,SCDs_scp]).reset_index(drop=True)\n",
    "le = LabelEncoder()\n",
    "label = le.fit_transform(folds_dup['label'])\n",
    "labels = le.fit_transform(folds[\"label\"])\n",
    "acc_sum = 0\n",
    "score_sum = 0\n",
    "acc_lst = []\n",
    "auc_lst = []\n",
    "y_lsts = []\n",
    "pred_lsts = []\n",
    "for i in range(5):\n",
    "    score_sum = 0\n",
    "    acc_sum = 0\n",
    "    set_seed(i)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for train_num, test_num in kf.split(fold_dup[\"scheme_num\"],label):\n",
    "        train_idxs = folds_dup[\"scheme_num\"].iloc[train_num]\n",
    "        train_idxs = folds[folds[\"scheme_num\"].isin(train_idxs)]\n",
    "        train_idx = train_idxs.index\n",
    "        test_idxs = folds_dup[\"scheme_num\"].iloc[test_num]\n",
    "        test_idxs = folds[folds[\"scheme_num\"].isin(test_idxs)]\n",
    "        test_idx = test_idxs.index\n",
    "        X_train, X_test = dfs[colss].iloc[train_idx], dfs[colss].iloc[test_idx]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "        lr_clf = LGBMClassifier(n_estimators=400, learning_rate=0.3, max_depth=3)\n",
    "        lr_clf.fit(X_train,y_train)      \n",
    "        pred = lr_clf.predict(X_test)\n",
    "        preds = lr_clf.predict_proba(X_test)\n",
    "        score = roc_auc_score(y_test, preds[:, 1])\n",
    "        y_lsts.extend(y_test)\n",
    "        pred_lsts.extend(preds)\n",
    "        auc_lst.append(float(score))\n",
    "\n",
    "fold1 = auc_lst[0] + auc_lst[0+5] + auc_lst[0+10] + auc_lst[0+15] + auc_lst[0+20]\n",
    "fold2 = auc_lst[1] + auc_lst[0+6] + auc_lst[0+11] + auc_lst[0+16] + auc_lst[0+21]\n",
    "fold3 = auc_lst[2] + auc_lst[0+7] + auc_lst[0+12] + auc_lst[0+17] + auc_lst[0+22]\n",
    "fold4 = auc_lst[3] + auc_lst[0+8] + auc_lst[0+13] + auc_lst[0+18] + auc_lst[0+23]\n",
    "fold5 = auc_lst[4] + auc_lst[0+9] + auc_lst[0+14] + auc_lst[0+19] + auc_lst[0+24]\n",
    "\n",
    "print(f'fold1:{fold1/5}')\n",
    "print(f'fold2:{fold2/5}')\n",
    "print(f'fold3:{fold3/5}')\n",
    "print(f'fold4:{fold4/5}')\n",
    "print(f'fold5:{fold5/5}')\n",
    "print(f'mean: {np.array(auc_lst).sum()/25}')\n",
    "print(f'AUC std: {np.std((fold1/5,fold2/5,fold3/5,fold4/5,fold5/5))}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('lcy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4c06100585aa2bac59a4f2ba66438908f16685636d3d9cc49c34f1f76cfb1cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
